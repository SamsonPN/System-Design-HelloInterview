{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c82ab4",
   "metadata": {},
   "source": [
    "# Consistent Hashing\n",
    "\n",
    "* used to distribute data across a cluster of servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f971436",
   "metadata": {},
   "source": [
    "## Naive: Simple Modulo Hashing\n",
    "\n",
    "* as you scale up, you might need to distribute your data across multiple databases instead of keeping it in one database\n",
    "    - this is called sharding\n",
    "    - this causes an issue: how do you know which database has which data?\n",
    "* naive approach: Simple Modulo Hashing\n",
    "    1. hash(event_id) = hash_number\n",
    "    2. hash_number % num_databases\n",
    "* this would tell us which database has what data\n",
    "    - Event #1234 → hash(1234) % 3 = 1 → Database 1\n",
    "    - Event #5678 → hash(5678) % 3 = 0 → Database 0\n",
    "    - Event #9012 → hash(9012) % 3 = 2 → Database 2\n",
    "* but what's the issue?\n",
    "    - if you decided to add another database, then: hash_number % (original_num_databases + 1)\n",
    "    - or if you need to delete a databse then: hash_number % (original_num_databases - 1)\n",
    "    - __this completely changes the modulo hash of the every id and causes a huge movement of data which could cause your app slowdown considerably or crash altogether__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80bcfb",
   "metadata": {},
   "source": [
    "## Consistent Hashing\n",
    "\n",
    "* solves the problem of data redistribution when adding/deleting an instance in a distrubted system\n",
    "* uses a \"hash ring\" to evenly distribute data\n",
    "    - create a ring with fixed number of points around it, e.g. [0, 100]\n",
    "        * normally, this would be the range: [0, $2^{32} - 1$], but it can also be bigger like [0, $2^{64} - 1$]\n",
    "    - then we distribute data across the hash ring\n",
    "        * if we have 4 databases, we'd put them at point 0, 25, 50, 75\n",
    "    - to find out which database has our data, we put the id through a hash function\n",
    "    - the number gives us the point on the range and we walk \"clockwise\" until we reach a database\n",
    "        * e.g. if hash(1234) = 16, we walk clockwise until we reach a database at 25\n",
    "* now when we add/delete a database, we only need to care about the hashes in a certain range\n",
    "    - e.g. if we added a database at point 90, then we only care about hashes from [75, 90]\n",
    "    - e.g. if we deleted a database at point 25, then we only care about hashes from [0, 25]\n",
    "    - this dramatically decreases the amount of data that needs to be redistributed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f3da7",
   "metadata": {},
   "source": [
    "## Virtual Nodes\n",
    "\n",
    "* there is still one problem left: if we remove a database, then the from a range would all be packed into the next database\n",
    "    - so one database will have significantly more data than the others\n",
    "* to solve this, we create virtual nodes associated with a database\n",
    "    - these virtual nodes occupy different parts of the hash ring instead of just being at one spot\n",
    "    - so we could have multiple virtual nodes of database 1 distributed across the hash ring\n",
    "* to get an even distribution of data:\n",
    "    - use a lot of virtual nodes for each database\n",
    "    - add randomness to hash the virtual nodes to prevent clustering and distribute them evenly across the ring\n",
    "* e.g. instead of hashing \"DB1\", we hash \"DB1-vn1\", \"db1-vn2\", etc\n",
    "    - so if DB1 fails, the data would be distributed evenly to other db-vn instead of just one database at one point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11472fc",
   "metadata": {},
   "source": [
    "## Consistent Hashing in the Real World\n",
    "\n",
    "* consistent hashing can be used to distribute data evenly across a cluster of servers, not just for databases\n",
    "    - these cluster of servers could be for caches, message brokers, or a set of application servers\n",
    "* Examples:\n",
    "    1. Redis Cluster: uses consistent hashing to distribute keys across nodes\n",
    "    2. Apache Cassandra: uses consistent hashing to distrubte data across the ring\n",
    "    3. Amazon's DynamoDB: uses consistent hashing under the hood\n",
    "    4. Content Delivery Network (CDNs): uses consistent hashing to determine which edge server should cache specific content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa57bf6",
   "metadata": {},
   "source": [
    "## When to use Consistent Hashing in an Interview:\n",
    "\n",
    "* most modern distributed systems handle sharding and data distribution for you\n",
    "    - when you use Redis, DynamoDB, or Cassandra in your system, you can just mention that these systems use consistent hashing under the hood to handle scaling\n",
    "* consistent hashing is crucial for infrastructure-focused interviews where you're asked to design distributed systems from scratch:\n",
    "    1. distributed database\n",
    "    2. distributed cache\n",
    "    3. distributed message broker\n",
    "* have to explain:\n",
    "    - why consistent hashing has advantages over simple modulo-based sharding\n",
    "    - how virtual nodes help achieve better load distribution across the system\n",
    "    - strategies for handling node failures and additions to the cluster\n",
    "    - how to address hot spots and implement effective data rebalancing strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
