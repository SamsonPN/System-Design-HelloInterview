{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e496a82",
   "metadata": {},
   "source": [
    "## Change log:\n",
    "\n",
    "* 5/12/2025: Finished from REST APIs -> WebRTC. Should start from Load Balancing section\n",
    "* 5/13/2025: Finished all sections. Might revisit to add more definitions for Networking Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e8eb7",
   "metadata": {},
   "source": [
    "# Networking Essentials\n",
    "\n",
    "* __packet__: basic unit of data sent over a network that can be part of a larger message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d492d5",
   "metadata": {},
   "source": [
    "## OSI Model\n",
    "\n",
    "* only focused on a couple of layers\n",
    "* basically abstraction and build on each other\n",
    "* Network Layer (3): IP\n",
    "    - most will use IP\n",
    "* Transport Layer (4): TCP/UDP\n",
    "    - built on top of IP\n",
    "* Application Layer (7): HTTP/Web sockets\n",
    "* for an HTTP request, these layers help each other\n",
    "* latency - back and forth\n",
    "* state -> a connection established/terminated\n",
    "    - how do you manage state?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff47fb",
   "metadata": {},
   "source": [
    "## Example: A Simple Web Request (HTTP)\n",
    "\n",
    "1. DNS Resolution: client uses a DNS to resolve the domain name of our destination into an IP address\n",
    "2. TCP Handshake: client uses a 3-way handshake to establish a TCP connection with the server\n",
    "    - SYN: client sends a SYN (synchronize) packet to the server to request a connection\n",
    "    - SYN-ACK: server sends a SYN-ACK (synchronize-acknowledge) packet that acknowledges the request\n",
    "    - ACK: the client sends an ACK (acknowledge) packet to establish the connection\n",
    "3. HTTP Request: when the TCP connection is established, the client sends an HTTP GET request to the server to reqeust web page\n",
    "4. Server Processing: the server prepares the response, aka the web page in this case to send back to the client\n",
    "    - this is the only latency that SWEs care about and control\n",
    "5. HTTP Response: the server sends back an HTTP response with the corresponding web page content\n",
    "6. TCP Teardown: after all the data is sent back with the HTTP response, the client and server must now close the TCP connection using a 4-way handshake\n",
    "    - FIN: client sends a FIN (finish) packet to the server to close the connection\n",
    "    - ACK: server acknowledges the FIN packet with an ACK packet\n",
    "    - FIN: server sends its own FIN packet to the client to close the connection from its side\n",
    "    - ACK: client acknowledges the server's FIN packet with its own ACK packet\n",
    "***\n",
    "* the connection between the client and server is a __state__ that both the client and server must maintain\n",
    "    - therefore, for every request we make from client to server, we must also set up all these packet transfers to make it happen\n",
    "    - this can be somewhat ignored...until it can't anymore since the nature of the handshakes causes some latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d645cf",
   "metadata": {},
   "source": [
    "## Layer 3 (Network)\n",
    "\n",
    "* IP = internet protocol\n",
    "    - gives usable names to nodes and routing\n",
    "* IPv4 = 4 byte\n",
    "    - internet uses this\n",
    "* IPv6 = 16 bytes (2 byte pairs)\n",
    "    - for external use\n",
    "    - we basically ran out of IPv4 addresses\n",
    "* in systems, IPs are assigned using a DHCP server (Dynamic Host Configuration Protocol) but they don't really mean much because people won't know about them\n",
    "    - this IPs are private\n",
    "* if you want your network to be accessible from anywhere on the internet, it needs to have an IP address allocated by the RIR (Regional Internet Registry)\n",
    "* Public IP: routers aware of them\n",
    "    - known to the world\n",
    "* Private IP: assign your nodes any name\n",
    "    - only have to remember where they are\n",
    "* for system design:\n",
    "    - public: for external components\n",
    "        * API gateway, load balance\n",
    "    - private: for everything else\n",
    "        * e.g. microservices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67697c96",
   "metadata": {},
   "source": [
    "## Layer 4 (Transport)\n",
    "\n",
    "* w/ IP, we can send __packets__ or data to a host but we are missing 2 things:\n",
    "    1. context: where data goes to/comes from\n",
    "        - can use ports but might not be enough\n",
    "    2. ordering of packets/delivery success\n",
    "        - not provided by IP itself but through protocols\n",
    "* 3 protocols:\n",
    "    1. TCP (default)\n",
    "    2. UDP\n",
    "    3. QUIC (similar to TCP but modern)\n",
    "\n",
    "### TCP (Transmission Control Protocol): guaranteed delivery / ordering but with overhead\n",
    "\n",
    "* establishes a connection through a __3-way handshake__ called a __stream__\n",
    "* __stream__: stateful connection between client and server\n",
    "* creates a sequence of packets (numbering)\n",
    "* if order of packets is wrong, know that something went wrong\n",
    "* identifies packet loss\n",
    "* TCP mitigates some network failures\n",
    "* __Key Characteristics of TCP:__\n",
    "    1. connection-oriented: establishes a dedicated connection before data transfer\n",
    "    2. reliable delivery: guarantees that data arrives in order and without errors\n",
    "    3. flow control: prevents overwhelming receivers with too much data\n",
    "    4. congestion control: adapts to network congestion to prevent collapse\n",
    "* __costs__: throughput/latency\n",
    "    - TCP needs to restransmit lost packets\n",
    "    - can take time\n",
    "* __USE TCP IF DATA INTEGRITY (GUARANTEE DELIVERY/ORDERING) IS CRITICAL, I.E. WHERE UDP IS NOT A GOOD FIT__\n",
    "\n",
    "### UDP (User Datagram Protocol): higher performance / spray + pray\n",
    "\n",
    "* cannot guarantee delivery, ordering, or duplicate protection\n",
    "    - e.g. zoom call, if connection dropped, it doesn't matter\n",
    "* datagrams contain info on where they came from (source IP address and port) and where they're going (destination IP address and port) but that's it\n",
    "* __Key Characteristics of UDP__:\n",
    "    1. connectionless: no handshake or connection setup\n",
    "    2. no guarantee of delivery: packets may be lost without notifcation\n",
    "    3. no ordering: packets may arrive in a different order than sent\n",
    "    4. lower latency: less overhead means faster transmission (recall all the packet transfers when establishing a TCP connection?)\n",
    "* __NEED FOR SPEED: USE UDP WHEN SPEED IS MORE IMPORTANT THAN BEING RELIABLE!__:\n",
    "    - for real-time apps, e.g. MMOs or online game\n",
    "    - the application can handle packet loss or out of order packets\n",
    "    - __browsers don't have widespread support of UDP outside of WebRTC__\n",
    "\n",
    "### TCP or UDP?\n",
    "\n",
    "* TCP by default unless __latency__ is very important\n",
    "* or you can handle packets missing/out of order\n",
    "* UDP __NOT__ supported by browsers natively\n",
    "* __you might choose UDP when:__\n",
    "    - low latency is critical (real-time applications, gaming)\n",
    "    - some data loss is acceptable (media streaming)\n",
    "    - handling high-volume telemetry (data sent from network devices that help in gauging its health/performance) or logs where occasional loss is acceptable\n",
    "    - don't need to support web browsers (or you have an alternative for that client)\n",
    "* modern apps often use both protocols for handling different things:\n",
    "    - web-based video conferencing app could use TCP/HTTP for signaling and authentication but UDP/WebRTC for the actual audio/video streams\n",
    "\n",
    "### TCP Vs. UDP Comparison\n",
    "\n",
    "| Feature | UDP | TCP |\n",
    "| :----- | :----- | :-----|\n",
    "| Connection | Connectionless | Connection Oriented |\n",
    "| Reliability | best-effort delivery | guaranteed delivery |\n",
    "| Ordering | no ordering guarantees | maintains order |\n",
    "| Flow Control | no | yes |\n",
    "| Congestion Control | no | yes |\n",
    "| Header Size | 8 bytes | 20 - 60 bytes |\n",
    "| Speed | Faster | Slower due to overhead |\n",
    "| Use Cases | streamining, gaming, VoIP | everything else |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a310129",
   "metadata": {},
   "source": [
    "## Layer 7 (Application)\n",
    "\n",
    "* application layer processes in the \"User Space\" (place where user applications run) whereas the lower layers are processed in the OS Kernel in the \"Kernel Space\"\n",
    "    - therefore, the application layer is more flexible and can be easily modified than the lower layers\n",
    "    - the lower layers are difficult to change but can be very efficient\n",
    "\n",
    "### HTTP/HTTPS: The Web's Foundation\n",
    "\n",
    "- de-facto standard for data communication on the web\n",
    "- __stateless protocol__: every request is independent and server does not maintain any data about previous requests or any data that could help with future requests\n",
    "- request/response\n",
    "    - request: HTTP verb determines intent of request\n",
    "        - headers = any info about request\n",
    "        - e.g. content-type or your own\n",
    "    - response: containing data, status code, and headers\n",
    "- __Key concepts of HTTP:__\n",
    "    1. Request methods: GET, POST, PUT, DELETE, etc\n",
    "    2. Status Codes: 200 OK, 404 Not Found, 500 Server Error, etc.\n",
    "    3. Headers: Metadata about the request or response\n",
    "    4. Body: the actual content being transferred\n",
    "- Common Request Methods:\n",
    "    - GET: requests data from the server\n",
    "        - should be __idempotent__ and don't have a body\n",
    "    - POST: send data to the server\n",
    "    - PUT: update data on the server\n",
    "    - PATCH: updatea resource partially\n",
    "    - DELETE: delete data from the server\n",
    "        - DELETE requests should be __idempotent__\n",
    "- Common Status Codes:\n",
    "    - Success (2xx):\n",
    "        - 200 OK: request was successful\n",
    "        - 201 Created: request was successful and a new resource was created\n",
    "    - Moved (3xx):\n",
    "        - 302 Found: requests resource has been moved temporarily\n",
    "        - 301 Moved Permanently: requested resource has been moved permanently\n",
    "    - Client Error (4xx):\n",
    "        - 404 Not Found: requested resource was not found\n",
    "        - 401 Unauthorized: request requires authentication\n",
    "        - 403 Forbidden: server understood the request but refuses to authorize\n",
    "        - 429 Too Many Requests: client has sent too many requests in a given amount of time\n",
    "    - Server Error (5xx):\n",
    "        - 500 Server Error: server encountered an error\n",
    "        - 502 Bad Gateway: server received an invalid response from the upstream server\n",
    "- can think of HTTP headers like key-value pairs\n",
    "    - e.g. the HTTP header _Accepts-Encoding_ provides clients a way to say that they can handle different types of content encoding\n",
    "        - servers can then respond with the most efficient encoding for that client with _Content-Encoding: X_\n",
    "        - this provides backward compatibility and graceful degradation\n",
    "- __content negotiation__: allows HTTP to be backwards/forwards compatible\n",
    "    - request might ask for JSON but if server doesn't have it, its header will indicate that it can send back plain text instead\n",
    "- __HTTPS__ adds a security layer (TLS/SSL) to encrypt communications and protect against eavesdropping and man-in-the-middle attacks\n",
    "    - this should be the default for public websites\n",
    "    - __word of warning for API creation__: never trust any request you receive without validating it first\n",
    "        - just because a request is encrypted doesn't mean that the request body itself doesn't contain information that could be malicious\n",
    "    \n",
    "#### REST API: representational state transfer \n",
    "- most common way to build APIs on top of HTTP\n",
    "- core principle: perform simple operations against __resources__ (like database tables or files on a server)\n",
    "- allows use of HTTP verbs to describe wanted operation/intent\n",
    "- resources => URLs associated w/ resources\n",
    "- organizing APIs around URLs and verbs\n",
    "    * e.g. User is a JSON object representing a user\n",
    "    * GET /users/{id} is a GET request that returns the User object as a response\n",
    "- __pretty much the default but not the most performant solution for high throughput services__\n",
    "    * JSON is pretty inefficient for serializing/deserializing data\n",
    "\n",
    "#### Graph QL: (REST alternative)\n",
    "- tries to solve issue of __under-fetching__ and __over-fetching__\n",
    "    - e.g. having to make multiple API calls to get all your needed data\n",
    "    - or changing API to send all necessary data (too slow)\n",
    "- GraphQL tells backend exactly what the front-end needs and no more\n",
    "    * can be a source of latency and complexity for the backend to be able to fulfill the query though\n",
    "- useful where frontend changes often or when lots of backend teams that frontend needs to call up\n",
    "- allow negotation between frontend and backend\n",
    "- for system design interviews:\n",
    "    * GraphQL shines when the design has to be adaptable to frequent changing requirements (requires flexibility) or the requirements are uncertain\n",
    "    * otherwise, the benefits are kind of murky since the requirements are fixed for these types of interviews\n",
    "\n",
    "#### gRPC (google Remote Procedure Call): protobuf + services:\n",
    "- protobufs = provide a schema that allows serializing of objects into binary representation\n",
    "    * protobufs allow you to save space\n",
    "- gRPC builds services on top of protobufs\n",
    "- gRPC makes serializing/de-serializing efficient\n",
    "    - REST sends data as JSON blobs that need to be parsed\n",
    "- gRPC can have 10x throughput compared to REST\n",
    "- __problems with gRPC__:\n",
    "    1. external clients and web browsers don't support gRPC natively\n",
    "    2. while working w/ binaries are efficient for servers, it makes it harder for developers to view data and debug it\n",
    "- __gRPC used for internal services b/c not widely used__\n",
    "    - wouldn't bring up gRPC unless we care a lot about performance\n",
    "    - but using REST for client-server and gRPC for internal services allows an optimal hybrid approach\n",
    "\n",
    "#### Server Sent Events:\n",
    "\n",
    "- push data to users as it's happening\n",
    "- extension on HTTP\n",
    "    * includes headers in response and body of response uses newlines to show how each event is separated\n",
    "    * b/c of headers, client can immediately parse response\n",
    "    * can push many messages as \"chunks\" in a __single response (same TCP connection)__ from the server\n",
    "    * also unidirectional flow from server to client\n",
    "- no infrastructure needed for SSE since they are basically HTTP requests\n",
    "- SSE connections are short-lived (30s - 60s)\n",
    "- SSE will automatically retry a new SSE connection\n",
    "- basically SSE built on HTTP requests allows for longer running requests that server can push to client (push notifications)\n",
    "- on older networks, SSE might not work reliably\n",
    "    * might batch up all SSE responses into a single response\n",
    "-  SSE is great when you want clients to __get notifications/events as soon as they happen__\n",
    "    * e.g. bidders up-to-date on current price of an auction\n",
    "\n",
    "#### Web Sockets:\n",
    "\n",
    "- useful for high frequency, persistent, and bi-directional communication between client and server\n",
    "    * real-time apps or games\n",
    "- __very powerful but require a lot of infrastructure which is expensive__\n",
    "    - think of polling or SSE solutions first before web sockets\n",
    "- websockets simulate TCP connections to browsers/other clients\n",
    "    - basically an exchange of binary blobs __in order__ and __reliably delivered__\n",
    "- involves a lot of __state__ but want to avoid statefulness in System Design interviews\n",
    "    * so to handle this, have an edge service that handles web sockets\n",
    "        - all users connect to service w/ websockets and the service makes requests to internal services, and those services send messages back via websockets\n",
    "- how web sockets work:\n",
    "    1. client initiates websocket handshake over HTTP with a backing TCP connection)\n",
    "    2. connection upgrades to WebSocket protocol; Websocket takesover the TCP connection\n",
    "        - this allows existing TCP connection to change L7 protocols\n",
    "        - very convenient since you can use existing HTTP session information like cookies, headers, etc\n",
    "    3. client and server can sendbinary messages to each other over the connection\n",
    "    4. connection stays open until explicitly closed\n",
    "\n",
    "### WebRTC: Real-time Communications (niche)\n",
    "\n",
    "- runs on UDP\n",
    "- __used for collaborative editors or audio + video communication between clients__\n",
    "- it's a Peer-to-Peer connection - allow clients to connect to each other\n",
    "- __avoid this in SD interviews unless used for audio + video calling or collaborative editors like google docs__\n",
    "- restrictions that don't allow peers to talk to each other:\n",
    "    * clients don't allow inbound connections for security reasons\n",
    "    * users are behind a NAT (network address translation) device does not allow them to be connected to directly\n",
    "- WebRTC standard has 2 methods to work around these restrictions:\n",
    "    * STUN: \"Session Traversal Utilities for NAT\"\n",
    "        - allows peers to establish routable addresses and ports\n",
    "    * TURN: \"Traversal Using Relays around NAT\"\n",
    "        - a relay service - a way to bounce requests through a central server which can then be routed to the appropriate peer\n",
    "- 4 steps for a WebRTC connection:\n",
    "    1. clients connect to a central signaling server to learn about their peers\n",
    "    2. clients reach out to a STUN server to get their public IP address and port\n",
    "    3. clients share this information with each other via the signaling server\n",
    "    4. clients establish a direct peer-to-peer connection and start sending data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c169549",
   "metadata": {},
   "source": [
    "## Vertical Scaling vs. Horizontal Scaling\n",
    "\n",
    "* vertical scaling: better hardware\n",
    "* horizontal more servers (expected in interviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1a517",
   "metadata": {},
   "source": [
    "## Load Balancers (problem introduced by horizontal scaling)\n",
    "\n",
    "1. spreads load between servers for more traffic\n",
    "2. allows for high availability -> redirects traffic from failed server to online one\n",
    "\n",
    "### Client-side Load Balancing:\n",
    "\n",
    "- client decides which server to talk to \n",
    "    * client aware of all servers via registry\n",
    "    * or ask server1 about other servers (redis clusters)\n",
    "- effective b/c no middleman\n",
    "    * client can choose fastest server without additional latency\n",
    "    * only need to sync list of servers with server registry\n",
    "- e.g. Redis Cluster:\n",
    "    * redis cluster nodes have a gossip protocol that shares info with each other about the cluster\n",
    "        - e.g. which nodes are present, their status, etc\n",
    "        - every node knows about every other node\n",
    "    * client connects to any node in the Redis cluster and will be able to gain information about every other node in it\n",
    "        - when reading/writing data, client can use the node it connected to to figure out the correct node to send the request\n",
    "        - if client sends to the wrong node, Redis will send back a `MOVED` response\n",
    "- e.g. DNS:\n",
    "    * when making a request to a domain name, the DNS resolver returns a rotated list of IP addresses for that domain\n",
    "    * each new request will have a different ordering of the IP addresses\n",
    "    * so DNS load balances for you since each IP address will hit a different server for different requests\n",
    "        - this also avoids single point of failures with load balancers\n",
    "        - you can have 2 load balancers in different data centers or regions and use DNS to rotate between them\n",
    "- useful when:\n",
    "    1. very few clients (internal microservices) that we have control of\n",
    "        - Redis Cluster client\n",
    "        - gRPC client-side load balancing for internal services\n",
    "    2. lots of clients but update delays are tolerated\n",
    "        - e.g. DNS b/c DNS is heavily cached (can take up to a day to propagate changes)\n",
    "        - we care about latency of updates b/c amount of time it takes will scale with number of clients we have to notify\n",
    "        - DNS has TTL (time to live) => amount of time entry is valid for\n",
    "            * makes it so that our updates cannot be faster than TTL\n",
    "- for interviews, client-side load balancing works really well for __internal microservers__\n",
    "    * native to gRPC so that's a plus if you use it\n",
    "\n",
    "### Dedicated Load Balancers:\n",
    "\n",
    "- useful for interacting w/ many external clients that need quick updates\n",
    "- layer between client and server\n",
    "- can be made of software or hardware\n",
    "\n",
    "#### Layer 4 Load Balancer: Transport Layer (TCP/UDP):\n",
    "- makes routing decisions based on IP addresses and ports __without looking at content of packets__\n",
    "- creates TCP connection to load balancer and that load balancer create a parallel TCP connection to that server\n",
    "    - we can pretend like this layer 4 load balancer doesn't exist\n",
    "    - almost like the client has a direct connection to the server\n",
    "    - layer 4 load balancers are really high performing\n",
    "        - don't care about looking at packets\n",
    "- Key Characteristics:\n",
    "    - maintain __persistent TCP connections__ between client and server\n",
    "        * if client has a TCP connection through an L4 load balancer, the same server will handle all subsequent requests within that TCP connection\n",
    "    - fast and efficient due to minimal packet inspection\n",
    "    - cannot making routing decisions based on application data\n",
    "    - typically used when raw performance is the priority\n",
    "- when to use it:\n",
    "    * __great for websocket connections and other protocols that require _persistent connections___\n",
    "    * great for high performance applications that don't require much application-level processing\n",
    "- for interviews:\n",
    "    * use L4 load balancer if you're using websockets\n",
    "    * otherwise, an L7 load balancer is a better fit\n",
    "    \n",
    "#### Layer 7 Load Balancer: Application Layer:\n",
    "- makes routing decisions based on content of each request\n",
    "- accepts HTTP requests and chooses a server to send requests to\n",
    "- more expensive\n",
    "- default for most cases except for websockets or stateful where a layer 4 load balancer is more acceptable\n",
    "- Key Characteristics:\n",
    "    * terminate incoming connections and create new ones to backend servers\n",
    "    * can route based on request content (URL, headers, cookies, etc)\n",
    "    * more CPU-intensive due to __packet inspection__\n",
    "    * provide more flexibility and features\n",
    "    * better suited for HTTP-based traffic\n",
    "- an L7 load balancer can route all API requests to one set of servers while routing web page requests to another\n",
    "    * or it can ensure that all requests from a specific user go to the same server based on a cookie\n",
    "- when to use it:\n",
    "    * great for HTTP-based traffic, which covers all of the protocols __except for websockets__\n",
    "- in interviews, L4 vs L7 load balancers come up for real-time features\n",
    "    * there are L7 load balancers that support connection-oriented protocols like websockets but for the most part, L4 load balancers are better for websocket connections\n",
    "\n",
    "#### Health Checks and Fault Tolerance\n",
    "- server tells load balancer that it's available and load balancer makes health check, and if server is healthy, will direct traffic to it\n",
    "- if server becomes unhealthy, load balancer stops sending traffic to it\n",
    "    * this makes load balancers __essential for high availability__\n",
    "- common approach for health check: TCP health check\n",
    "    * layer 7 health check might make an HTTP request\n",
    "    * if receives status 200, then it's healthy\n",
    "        - if status 500 or no response, unhealthy\n",
    "\n",
    "#### Load Balancing Algorithms:\n",
    "- __benefit of using a dedicated load balancer over client-side load balancer is having more choices of algorithms for distributing traffic__\n",
    "- load balancing algorithms for __stateless__ or simply request/response\n",
    "    - round robin: requests distributed sequentially across servers\n",
    "        * send to server 1, then 2, then 3, etc\n",
    "    - random allocation\n",
    "    - by least connections -> only allocate new connections to server w/ least connections\n",
    "        - good for getting new server up to speed\n",
    "        - good for long-running/stateful connections b/c connections could last hour+ and this guarantees more even distribution\n",
    "    - least response time: requests go to the servers with the fastest response times\n",
    "    - IP hash: client IP determines which server receives the request\n",
    "        * useful for session persistence\n",
    "- __typically, Round Robin or Random algorithm are appropriate, especially forstateless applications__\n",
    "- when services require a persistent connection (SSE or WebSocket connections), use Least Connections b/c it avoids situations where single server gradually accumulates all of the active connections\n",
    "\n",
    "#### Real-World Implementations:\n",
    "- Hardware Load Balancers: Physical Devices like F5 Networks BIG-IP\n",
    "- Software Load Balancers: HAProxy, NGINX, Envoy\n",
    "- Cloud Load Balancers: AWS ELB/ALB/NLB, Google Cloud Load Balancing, Azure Load Balancing\n",
    "- enterprise hardware load balancers can support 100s of millions of requests per second whereas software load balancers are more limited\n",
    "    * if you find that load balancer throughput is large, mentioning hardware load balancers is a good way out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06bc06c",
   "metadata": {},
   "source": [
    "## Regionalization and Latency\n",
    "\n",
    "- distances between can requests can hamper latency (how far a request can travel)\n",
    "- global scale system = global scale traffic\n",
    "- to solve these issues:\n",
    "    1. co-locate data: keep  core of data + processing close together\n",
    "    2. get services closests to user as possible\n",
    "        - have some cases like youtube/reddit where users from one region can access data of others so having data be closest to user is not always possible\n",
    "        - but you have some options:\n",
    "            1. have that data be local to where it is used the most\n",
    "            2. save data locally but replicate that data to other regions\n",
    "            3. use a CDN -> used as a cache to serve data quickly to users that are closest to it\n",
    "                - helps reduce load on backend\n",
    "                - not all data can be cached but can call the origin server (actual backend) to get that data\n",
    "\n",
    "### Content Delivery Networks (CDNs):\n",
    "- networks of servers strategically located around the world\n",
    "- these networks have 100s/1000s of different cities where they have servers\n",
    "    * these servers make up what is referred to as an \"edge location\"\n",
    "- use of CDNs is only possible because of __caching__\n",
    "    * if data doesn't change a lot or doesn't need to be updated frequently, then we can cache it at the edge server and return it from there\n",
    "    * __effective for static content like images, videos, and other assets__\n",
    "- when to use it:\n",
    "    * when we have very cacheable data that needs to be queried across the globe\n",
    "    * using a CDN as a cache (e.g. search results on Facebook) allows us to both minimize latency and reduce load on backend servers\n",
    "\n",
    "### Regional Partitioning:\n",
    "- can partition data by region so that we only have data relevant to that region\n",
    "    * e.g. users in Miami only care about Uber drivers in Miami or neighboring cities/area, not New York\n",
    "- can bundle nearby cities into a local region (e.g. Northeast US)\n",
    "    * each one can have its own database hosted on distinct servers in that location\n",
    "    * and the servers handling requests can be close to those database servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abc91b",
   "metadata": {},
   "source": [
    "## Timeouts, Backoffs, Retries\n",
    "\n",
    "- i.e. how you handle failures in your system\n",
    "- timeouts allow connection to give up and retrieve an error message\n",
    "    - have to be long enough so that the request can be fulfilled but not too long that the client has to wait\n",
    "- when there's a failure/timeout the obvious thing to do is retry\n",
    "    - naive approach: retry every x seconds\n",
    "        - naive because server hasn't changed much\n",
    "        - also has a \"bunching\" behavior\n",
    "        - https://encore.dev/blog/thundering-herd-problem\n",
    "    - backoff approach (often times exponential backoff):\n",
    "        - subsequent retries take longer to start\n",
    "        - first retry = quick, but after retries takes more time in between\n",
    "        - but that \"bunching\" behavior still happens where multiple clients make a request at the same time but now with longer time in-between\n",
    "    - jitter approach (randomness):\n",
    "        - randomize retry delays which solves the \"bunching\" issue since multiple clients have less of a chance to call the server at the same time\n",
    "        - helps distribute load\n",
    "        - https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/\n",
    "- __gold standard for interviews__: timeouts and retries with exponential backoff and jitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d046a",
   "metadata": {},
   "source": [
    "### Idempotency:\n",
    "- retries with side effects can introduce problems\n",
    "    * e.g. payment system charging user\n",
    "    * if you retry request multiple times, they can be overcharged\n",
    "- idempotent APIs ensure this doesn't happen\n",
    "    * idempotency = produce the same result every time if called multiple times\n",
    "    * HTTP GET is a common example of this\n",
    "        - content returned by a GET request may change but fetching the content does not change the state of the system\n",
    "- when it comes to writing data, use an __idempotency key__\n",
    "    * idempotency key: unique identifier for a request that can ensure that the same request is idempotent\n",
    "    * e.g. for our payment system, we can use the user's ID and current date if we assume they only buy 1 item per day\n",
    "        - on the server, we can check if we've already processed or are currently processing a request with that idempotency key and process it only once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e676121",
   "metadata": {},
   "source": [
    "## Cascading Failures:\n",
    "\n",
    "- mostly in senior/staff-level interviews\n",
    "- a failure or a component at limited capacity in your system causes a domino-effect of failures\n",
    "\n",
    "### Circuit Breakers:\n",
    "- to deal with this, you use circuit breakers like the ones in our house\n",
    "- in software, a circuit breaker trips when a failure exceeds a certain level\n",
    "    - halts operations but resets after a time to allow subsequent components to recover\n",
    "    - allows failing in an \"obvious\" way and notifies that something is failing downstream\n",
    "- here's how they work:\n",
    "    1. circuit breaker monitors for failures when calling external services\n",
    "    2. when failures exceed a threshold, the circuit \"trips\" to an open state\n",
    "    3. while open, requests immediately fail without attempting the actual call\n",
    "    4. after a timeout period, the circuit transitions to a \"half-open\" state\n",
    "    5. a test request determines whether to close the circuit or keep it open\n",
    "- circuit breakers provide many advantages:\n",
    "    * fail fast: quickly reject requests to failing services instead of waiting for timeouts\n",
    "    * reduce load: prevent overwhelming already sturggling services with more requests\n",
    "    * self-healing: automatically test recovery without full traffic load\n",
    "    * improved user experience: provide fast fallbacks instead of hanging UI\n",
    "    * system stability: prevent failures in one service from affecting the entire system\n",
    "- where to use it:\n",
    "    * great response when asked about reliability, failure modes, or disaster recovery\n",
    "- example sites to apply circuit breakers:\n",
    "    * external API calls to third-party services\n",
    "    * database connections and queries\n",
    "    * service-to-service communication in microservices\n",
    "    * resource-intensive operations that might time out\n",
    "    * any network call that could fail or become slow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
