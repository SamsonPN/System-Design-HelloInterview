{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d871cef9",
   "metadata": {},
   "source": [
    "# Kafka\n",
    "\n",
    "* Apache Kafka: open-source distributed event streaming platform\n",
    "    - used as either a message queue or as a stream processing system\n",
    "    - high performance, scalable, and durable\n",
    "    - can handle a lot of data in real-time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11bf42",
   "metadata": {},
   "source": [
    "## Basic Terminology and Architecture\n",
    "\n",
    "* `broker`: the physical/virtual servers that host the Kafka `partitions`\n",
    "    - they store data and serve clients\n",
    "    - Kafka clusters are made up of multiple brokers\n",
    "* `partitions`: ordered, immutable sequence of messages\n",
    "    - like an append-only log file\n",
    "    - these help Kafka scale since they allow producers to append messages while allowing consumers to process them in parallel\n",
    "* `topics`: logical grouping of partitions\n",
    "    - e.g. partitions for basketball matches or soccer matches, etc\n",
    "    - you publish/subscribe to data in Kafka using topics\n",
    "    - topics are multi-producer: can have many producers writing data to it\n",
    "    - topics can have multiple partitions that are in different brokers\n",
    "* `producers`: they write data to the topics\n",
    "* `consumers`: read data from topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d50587",
   "metadata": {},
   "source": [
    "## How Kafka Works\n",
    "\n",
    "* when an event occurs, Producers respond by creating messages to be published\n",
    "* a message consists of the following:\n",
    "    - value (required)\n",
    "    - key (optional): determines which partition message goes to\n",
    "    - timestamp (optional): used to order messages in partition\n",
    "    - headers (optional): similar to HTTP headers that can be used to store metadata about the message\n",
    "\n",
    "### What Happens When a Message is Published?\n",
    "* when a message is published to a Kafka topic, there are 2 steps:\n",
    "1. `Partition Determination`: if the message provides a key, this key is put through a hashing function and assigned to a specific partition\n",
    "    - __this always ensures that messages with the same key go to the same partition__\n",
    "    - if no key, Kafka will round-robin the message to a partition\n",
    "    - or will use partitioning logic provided by the producer configuration\n",
    "2. `Broker Assignment`: once a partition is determined, Kafka has to find out which broker contains that partition\n",
    "    - remember that a broker is a server that hosts the partitions\n",
    "    - the Kafka cluster metadata contains mappings of brokers => partitions\n",
    "    - this metadata is maintained by the Kafka controller (role within the broker cluster)\n",
    "* once a broker for the partition is found, Kafka will send the message directly to the target partition on that broker\n",
    "\n",
    "### Benefits of Partitions as an Append-Only Log File\n",
    "\n",
    "* messages are appended to the end of partition like a log file\n",
    "* this provides several benefits:\n",
    "1. __Immutability__: once a message is written to the partition, it cannot be changed or deleted\n",
    "    - this improves performance and reliability b/c:\n",
    "        1. replication is simpler\n",
    "        2. speeds up recovery process\n",
    "        3. avoids consistency issues common in systems where data can be changed\n",
    "2. __Efficiency__: since the only operation is append, this minimizes disk seek times which are a major bottleneck in many storage systems\n",
    "3. __Scalability__: helps with horizontal scaling\n",
    "    - more partitions can be added and distributed across a cluster of brokers\n",
    "    - and each partition is replicated across multiple brokers for more fault tolerance\n",
    "\n",
    "### Offsets\n",
    "\n",
    "* each message has an offset that determines its position in the Kafka partition\n",
    "    - think of it like an index in an array\n",
    "* offsets are used by consumers to track which messages they've read already, like a bookmark\n",
    "    - when consumers read messages, they maintain the current offset\n",
    "    - consumers will periodically commit offsets back to Kafka\n",
    "        * this allows consumers that failed/restarted to resume where they left off before the failure/restart\n",
    "\n",
    "### Replication\n",
    "\n",
    "* replication helps ensure availability and durability of messages\n",
    "* Kafka uses a `leader-follower model` of replication\n",
    "1. `Leader Replica Assignment`: each partition has a designated Leader replica which resides on a broker\n",
    "    - responsible for ALL read/write requests for the partition\n",
    "    - assignment of Leader Replica handled by the cluster controller\n",
    "        * it ensures that each partition's leader replica is distributed across the cluster to balance load\n",
    "2. `Follower Replication`: there are several follower replicas for a partition\n",
    "    - their only responsibility is to replicate data from their respective leader replica\n",
    "    - follower replicas for a specific partition can reside in different brokers, not just the one their leader replica is in\n",
    "    - they are essentially backups for the leader replica in case it fails\n",
    "        - the most up-to-date follower replica will be promoted to the leader replica in case of failures\n",
    "3. `Synchronization and Consistency`: followers continuously sync with the leader replica to get the latest messages\n",
    "    - very important for maintaining consistency across the cluster\n",
    "    - if leader replica fails, follower replica gets promoted => minimizes downtime and data loss\n",
    "4. `Controller's Role in Replication`: manages replication process\n",
    "    - monitors health of all brokers and manages leadership and replication dynamics\n",
    "    - if a broker fails, it reassigns the leader  role to one of the in-sync follower replicas for continued availability\n",
    "\n",
    "### How Consumers Read Messages\n",
    "\n",
    "* consumers read messages from Kafka topics used a `pull-based model`\n",
    "    - consumers poll the broker for new messages at set intervals\n",
    "* this is by design and allows for several benefits:\n",
    "1. lets consumers control their consumption rate\n",
    "2. simplifies failure handling\n",
    "3. prevents overwhelming slow consumers\n",
    "4. enables efficient batching\n",
    "* [Apache Kafka Pull Design](https://kafka.apache.org/documentation.html#design_pull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22fb4d",
   "metadata": {},
   "source": [
    "## When to use Kafka in your Interview\n",
    "\n",
    "* can be used as a `message queue` or `stream`\n",
    "    - message queue: consumers pull messages from the queue and process them when they are ready\n",
    "    - stream: consumers continuously consume and process messages as they arrive in real-time, like drinking from a flowing river\n",
    "* when to use a `message queue`?\n",
    "    - when you can process things asynchronously\n",
    "        * i.e. uploading a YouTube video\n",
    "        * when the system has time to process the video, it will do so\n",
    "    - when you want messages to arrive in order (that's what a queue is for!!!)\n",
    "    - when you want to decouple producers from consumers to scale them independently\n",
    "        * we do this because the producer might be producing messages faster than a consumer can process them\n",
    "        * so we can append whatever messages the producer makes into the queue but it's ultimately up to the consumer when it is ready to actually process them\n",
    "        * this is common so that one service can't take down another\n",
    "* when to use a `stream`?\n",
    "    - when you need to continously and immediately process incoming data, like a real time flow\n",
    "        * i.e. Ad Click Aggregator where we aggregate click data in real-time\n",
    "    - when you need messages to be processed by multiple consumers at the same time\n",
    "        * i.e. FB Live Comments where we send comments to multiple consumers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4e9d6",
   "metadata": {},
   "source": [
    "## What you should know about Kafka for System Design Interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7ebef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
