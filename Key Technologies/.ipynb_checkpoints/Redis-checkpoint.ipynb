{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513e8c34",
   "metadata": {},
   "source": [
    "# Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da11d91",
   "metadata": {},
   "source": [
    "## Redis Basics\n",
    "\n",
    "* Redis is a self-described \"data structure store\" that's in-memory and single-threaded\n",
    "    * Single-Threaded: simplifies order of operations and makes executing them really fast\n",
    "        - the first request is always the first one served and all subsequent requests have to wait\n",
    "        - you don't have to worry about complex locking mechanisms\n",
    "            * don't have multiple threads to coordinate for access to a single resource\n",
    "            * no deadlocks since no other threads or shared resources to wait on\n",
    "        - avoids race conditions since operations only happen once at a time\n",
    "    * In-Memory: makes operations very fast since it avoids the overhead of reading data from disk into memory through disk I/O\n",
    "        - but we have a tradeoff of speed for durability, meaning data saved in memory will not persist\n",
    "        - there are ways to minimze data loss but you don't get the same guarantees compared to a relational database\n",
    "* fundamental data structures supported by Redis:\n",
    "    - strings\n",
    "    - hashes (objects)\n",
    "    - lists\n",
    "    - sets\n",
    "    - sorted sets (priority queues)\n",
    "    - bloom filters\n",
    "    - geospatial indexes\n",
    "    - time series\n",
    "* also supports different communication patterns like Pub/Sub and Streams\n",
    "* __core structure underneath Redis is a key-value store__\n",
    "    - keys = strings\n",
    "    - values = any data structures supported by Redis\n",
    "    - __the way you organize the keys will be the way your organize your data and scale your Redis cluster__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deffea7",
   "metadata": {},
   "source": [
    "## Infrastructure Configurations\n",
    "\n",
    "* can be run as a single node, a single node with a high availability (HA) replica, or as a cluster\n",
    "* for clusters, the Redis clients have a set of \"hash slots\"\n",
    "    - these hash slots map keys to a specific node\n",
    "    - e.g. if node1 has keys [0,100] and you want to look up info on key 50, you know that node1 would have it\n",
    "* gossip protocol: each node in a cluster is aware of other nodes\n",
    "    - if you send a request to the wrong node to lookup a key, that node will tell you the correct node to query\n",
    "* Redis clusters are pretty basic and thus are limited\n",
    "    - e.g. Redis expects all data for a given request to be on a single node\n",
    "    - reason being, you cannot have multi-key operations across multiple hash slots\n",
    "    - since hash slots map to nodes, if you try to work with multiple keys, you cannot guarantee that those keys will belong to the same hash slot and thus the same node by extension\n",
    "    - this is only a limitation in cluster-mode. without clustering, all keys would be on the same node, and thus would support multi-key operations\n",
    "    - [Why are multi-key operations not supported on Redis cluster?](https://groups.google.com/g/redis-db/c/un6KAUaMDLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e7778",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "* Redis is very fast\n",
    "* O(100k) writes per second\n",
    "* read latency = microsecond range\n",
    "* since it's so fast, some anti-patterns in other database systems is feasible with Redis\n",
    "    - e.g. really bad: 100 SQL requests to generate a list of items vs writing 1 SQL query for all the data\n",
    "    - with Redis, this is still a terrible idea but with much less overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb519450",
   "metadata": {},
   "source": [
    "## Capabilities\n",
    "\n",
    "### Redis as a Cache:\n",
    "\n",
    "* most common use for Redis\n",
    "* basically just use it as a regular key-value store\n",
    "    - the root keys literally maps to a value and not to a data structure containing your value\n",
    "        * i.e. the root key is your lookup key\n",
    "    - can distribute this hash map across nodes in a cluster pretty easily since keys map to hash slots which map to nodes\n",
    "        * would just have to rebalance the cluster\n",
    "        * [Hash Slot Resharding and Rebalancing for Redis Cluster](https://severalnines.com/blog/hash-slot-resharding-and-rebalancing-redis-cluster/)\n",
    "* each key would have a TTL (Time-To-Live)\n",
    "    - Redis guarantees you'll never read a value of a key after the TTL has expired\n",
    "    - TTL used as an eviction policy\n",
    "    - depending on the eviction policy, if you want to create more entries in the cache but are running out of memory, Redis would evict entries with TTLs that are the closest to expiring\n",
    "        * \"volatile-ttl: Evict keys with the expire field set to true that have the shortest __remaining__ time-to-live (TTL) value.\"\n",
    "* __doesn't solve the Hot Key Problem though__\n",
    "\n",
    "### Redis as a Distributed Lock:\n",
    "\n",
    "* a distributed lock controls access to a shared resource like a mutex but for distributed systems\n",
    "* an example:\n",
    "    - simple distributed lock with timeout\n",
    "    - when we want to get the lock, we run the `INCR` command\n",
    "    - if response = 1, we own the lock\n",
    "    - if response > 1, have to wait and retry again until lock is released\n",
    "    - when someone is done with the lock, we can `DEL` the keys so others can use it\n",
    "* more sophisticated locks in Redis can use the Redlock Algorithm\n",
    "\n",
    "### Redis for Leaderboards:\n",
    "\n",
    "* we can make use of Redis' __SortedSets__ which we can query in O(logn) time\n",
    "    - for scaling, Redis is better than SQL Databases because of its high write throughput and low read latency\n",
    "    - Redis is in-memory so it's much faster than reading from disk\n",
    "    - Redis is single-threaded so don't have to worry about locks\n",
    "    - Also doesn't have to parse queries, update indexes, handle joins and transactions, etc.\n",
    "* an example:\n",
    "    - want to find posts which contain  keyword (e.g. \"tiger\") which has the most likes\n",
    "    - can use SortedSets to maintain this list of words by adding the tweet and number of likes into it\n",
    "    \n",
    "### Redis for Rate Limiting:\n",
    "\n",
    "* common algorithm for Rate Limiting: Fixed-Window Rate Limiter\n",
    "    - i.e. # of requests does not exceed N over some fixed window of time W\n",
    "* create a key for our rate limiter\n",
    "    - value = # of requests so far\n",
    "    - when request comes in, we increment that value\n",
    "    - if the response > N, we wait\n",
    "    - otherwise, we can make the request\n",
    "    - we `EXPIRE` the key after the time period, W, so that the value is reset\n",
    "\n",
    "### Redis for Proximity Search\n",
    "\n",
    "* Redis natively supports geospatial indexes\n",
    "* the search command, GEOSEARCH, runs in O(n + log(m)) time where n = # of elements in the radius and m = # of items inside the shape\n",
    "\n",
    "\n",
    "### Redis for Event Sourcing\n",
    "\n",
    "*  Redis stream = append-only logs\n",
    "    - want to use this to add items to a log\n",
    "    - then have some distributed mechanism to consume items from these logs\n",
    "* an example:\n",
    "    - want to have an asynchronous work queue\n",
    "    - add items to these queue to have them processed\n",
    "    - we have workers that work on these items but sometimes they can fail\n",
    "    - to solve this, we can use a Consumer Group (CG)\n",
    "    - the CG attaches to the stream and keeps track of the item we're currently working on\n",
    "    - it distributes that work to a Worker\n",
    "    - if the worker fails, the CG will reclaim the item and give it to a new worker\n",
    "\n",
    "### Redis for Pub/Sub\n",
    "\n",
    "* Redis natively supports a publish/subscribe (Pub/Sub) messaging pattern\n",
    "    - usefulfor chat systems, real-time notifications, or when we want to decouple message producers from message consumers\n",
    "    - Redis pub/sub is also now shared which allows for scalability\n",
    "* client subscribes to channel => receives any messages published to that channel\n",
    "    - only as long as connection remains open\n",
    "* pub/sub clients use a single connection to each node in the cluster (rather than a connection per channel)\n",
    "    - i.e. # of connections = # of nodes in a cluster\n",
    "    - don't need millions of connections if you have millions of channels!\n",
    "* __Redis Pub/Sub is NOT DURABLE__\n",
    "    - delivery = at most once\n",
    "        * if subscriber is offline when the message is published, it won't receive it\n",
    "    - use Kafka/RabbitMQ or Redis Streams when you need message persistence, delivery guarantees,or ability to replay missed messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e75f8",
   "metadata": {},
   "source": [
    "## Shortcomings and Remediations\n",
    "\n",
    "### Hot Key Issues\n",
    "\n",
    "* the Hot Key Issue refers to a situation where a small number of keys receives a disproportionately high amount of traffic compared to others\n",
    "* an example:\n",
    "    - have items in an ecommerce store\n",
    "    - have lots of nodes and spread items evenly\n",
    "    - one item starts getting a large amount of traffic\n",
    "    - node with that item has way higher load than the rest of the nodes\n",
    "    - server will start failing\n",
    "* possible solutions:\n",
    "    - add an in-memory cache in the clients so that we reduce number of requests to Redis\n",
    "    - store the same data in multiple keys and randomize requests so they spread across the cluster\n",
    "    - add read replica instances and dynamically scale these with load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
