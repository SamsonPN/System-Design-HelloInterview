{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a933cac7",
   "metadata": {},
   "source": [
    "# Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b44dbf",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "### Documents\n",
    "\n",
    "* basically JSON objects that you search over\n",
    "* each one has a unique ID\n",
    "```\n",
    "{\n",
    "      \"id\": \"XYZ123\",\n",
    "      \"title\": \"The Great Gatsby\",\n",
    "      \"author\": \"F. Scott Fitzgerald\",\n",
    "      \"price\": 10.99,\n",
    "      \"createdAt\": \"2024-01-01T00:00:00.000Z\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Index\n",
    "\n",
    "* a collection of documents\n",
    "* searches are done against Indexes which return a list of documents\n",
    "\n",
    "### Mappings and Fields\n",
    "\n",
    "* Mapping = schema of the Index that defines the fields the Index can have and its data type\n",
    "    - determines which field is searchable\n",
    "* example of mapping:\n",
    "    - keyword type = treats entire thing as a single value, a single token\n",
    "        * if your id = 123, you can only search for it if your query = 123,\n",
    "        * it would not return anything if your query = 12\n",
    "        * think Hash map\n",
    "    - text type = words or phrases of the text can be searched for\n",
    "        * e.g. \"the quick brown fox\" can be searched for with \"quick brown\"\n",
    "        * think Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f67922",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"properties\": {\n",
    "    \"id\": { \"type\": \"keyword\" },\n",
    "    \"title\": { \"type\": \"text\" },\n",
    "    \"author\": { \"type\": \"text\" },\n",
    "    \"price\": { \"type\": \"float\" },\n",
    "    \"createdAt\": { \"type\": \"date\" }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83776130",
   "metadata": {},
   "source": [
    "* Mappings can affect the performance of your cluster\n",
    "    - too many fields in the Mapping that aren't actually searchable increases memory overhead of Index = wastes memory!!!\n",
    "    - __you are allowed to not have every documents' fields in your Mapping__\n",
    "    - the `dynamic` setting determines how to go about adding new fields into the Mapping\n",
    "        * dynamic: true => adds new fields into Mapping if it encounters a new field\n",
    "        * dynamic: false => disregards new fields in new documents not in the Mapping, i.e. doesn't add them to Mapping\n",
    "        * dynamic: strict => will throw an error if it encounters new fields in new documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "// PUT users_index\n",
    "{\n",
    "    \"mappings\": {\n",
    "        \"dynamic\": false, // IMPORTANT\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "            \"createdAt\": {\n",
    "                \"type\": \"date\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// POST users_index/_doc\n",
    "{\n",
    "    \"name\": \"Alice\",\n",
    "    \"createdAt\": \"2024-01-01T12:00:00Z\",\n",
    "    \"occupation\": \"Engineer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6feb5ef",
   "metadata": {},
   "source": [
    "## Basic Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a143f5",
   "metadata": {},
   "source": [
    "### Create an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84873f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// PUT /books\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"number_of_shards\": 1,\n",
    "    \"number_of_replicas\": 1\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f83bf7",
   "metadata": {},
   "source": [
    "### Set a Mapping\n",
    "\n",
    "* if most of the fields in your data are not searchable, you can create a Mapping for the index without relying on the dynamic mapping\n",
    "* you can see that one of the fields has a type of `nested`\n",
    "    - this means that these are nested documents with their own fields\n",
    "    - your decision on when to nest something is entirely dependent on its query patterns\n",
    "        * if something is queried often but updated infrequently, you might want to nest it\n",
    "        * this is similar to normalization/denormalization tradeoff with SQL databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3802af",
   "metadata": {},
   "outputs": [],
   "source": [
    "// PUT /books/_mapping\n",
    "{\n",
    "  \"properties\": {\n",
    "    \"title\": { \"type\": \"text\" },\n",
    "    \"author\": { \"type\": \"keyword\" },\n",
    "    \"description\": { \"type\": \"text\" },\n",
    "    \"price\": { \"type\": \"float\" },\n",
    "    \"publish_date\": { \"type\": \"date\" },\n",
    "    \"categories\": { \"type\": \"keyword\" },\n",
    "    \"reviews\": {\n",
    "      \"type\": \"nested\", // IMPORTANT!!!\n",
    "      \"properties\": {\n",
    "        \"user\": { \"type\": \"keyword\" },\n",
    "        \"rating\": { \"type\": \"integer\" },\n",
    "        \"comment\": { \"type\": \"text\" }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646af2f",
   "metadata": {},
   "source": [
    "### Add Documents\n",
    "\n",
    "*  simple POST request to /_doc endpoint\n",
    "* each request will return a document ID and data on how it persisted across the cluster\n",
    "    - the `version` field can be used to update the documents atomically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8154bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "// POST /books/_doc\n",
    "{\n",
    "  \"title\": \"The Great Gatsby\",\n",
    "  \"author\": \"F. Scott Fitzgerald\",\n",
    "  \"description\": \"A novel about the American Dream in the Jazz Age\",\n",
    "  \"price\": 9.99,\n",
    "  \"publish_date\": \"1925-04-10\",\n",
    "  \"categories\": [\"Classic\", \"Fiction\"],\n",
    "  \"reviews\": [\n",
    "    {\n",
    "      \"user\": \"reader1\",\n",
    "      \"rating\": 5,\n",
    "      \"comment\": \"A masterpiece!\"\n",
    "    },\n",
    "    {\n",
    "      \"user\": \"reader2\",\n",
    "      \"rating\": 4,\n",
    "      \"comment\": \"Beautifully written, but a bit sad.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "// RESPONSE\n",
    "{\n",
    "  \"_index\": \"books\",\n",
    "  \"_id\": \"kLEHMYkBq7V9x4qGJOnh\",\n",
    "  \"_version\": 1, // IMPORTANT!!!\n",
    "  \"result\": \"created\",\n",
    "  \"_shards\": {\n",
    "    \"total\": 2,\n",
    "    \"successful\": 1,\n",
    "    \"failed\": 0\n",
    "  },\n",
    "  \"_seq_no\": 0,\n",
    "  \"_primary_term\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3c198",
   "metadata": {},
   "source": [
    "### Updating Documents\n",
    "\n",
    "* similar to creating a document but requires you specify the document ID in the URL\n",
    "* if you pass in `version` as the query parameter, you prevent overwriting your changes\n",
    "    - Elasticsearch will check the version number of the document with the one in the query parameter\n",
    "    - if they both match, it can proceed to update\n",
    "    - if not, it will return an error\n",
    "    - it's a really simple example of __Optimistic Concurrency Control__\n",
    "* * can use the `_update` endpoint to only update some fields and not the entire document at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8356518",
   "metadata": {},
   "outputs": [],
   "source": [
    "// PUT /books/_doc/kLEHMYkBq7V9x4qGJOnh\n",
    "{\n",
    "  \"title\": \"To Kill a Mockingbird\",\n",
    "  \"author\": \"Harper Lee\",\n",
    "  \"description\": \"A novel about racial injustice in the American South\",\n",
    "  \"price\": 13.99,\n",
    "  \"publish_date\": \"1960-07-11\",\n",
    "  \"categories\": [\"Classic\", \"Fiction\"],\n",
    "  \"reviews\": [\n",
    "    {\n",
    "      \"user\": \"reader3\",\n",
    "      \"rating\": 5,\n",
    "      \"comment\": \"Powerful and moving.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "// PUT /books/_doc/kLEHMYkBq7V9x4qGJOnh?version=1\n",
    "...\n",
    "\n",
    "// UPDATE ONLY PARTS OF THE DOCUMENT\n",
    "// POST /books/_update/kLEHMYkBq7V9x4qGJOnh\n",
    "{\n",
    "  \"doc\": {\n",
    "    \"price\": 14.99\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df306640",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "* query syntax is very similar to SQL but JSON-based\n",
    "* might have issues with body in a GET request\n",
    "    - but you can put it into the query string\n",
    "    - or use the POST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "// GET /books/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"Great\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// GET /books/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        { \"match\": { \"title\": \"Great\" } },\n",
    "        { \"range\": { \"price\": { \"lte\": 15 } } }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// GET /books/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"nested\": {\n",
    "      \"path\": \"reviews\",\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            { \"match\": { \"reviews.comment\": \"excellent\" } },\n",
    "            { \"range\": { \"reviews.rating\": { \"gte\": 4 } } }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6105d15",
   "metadata": {},
   "source": [
    "* response will have:\n",
    "    - document ids\n",
    "    - scores based on relevance\n",
    "    - source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"took\": 7,\n",
    "  \"timed_out\": false,\n",
    "  \"_shards\": {\n",
    "    \"total\": 5,\n",
    "    \"successful\": 5,\n",
    "    \"skipped\": 0,\n",
    "    \"failed\": 0\n",
    "  },\n",
    "  \"hits\": {\n",
    "    \"total\": {\n",
    "      \"value\": 2,\n",
    "      \"relation\": \"eq\"\n",
    "    },\n",
    "    \"max_score\": 2.1806526,\n",
    "    \"hits\": [\n",
    "      {\n",
    "        \"_index\": \"books\",\n",
    "        \"_type\": \"_doc\",\n",
    "        \"_id\": \"1\",\n",
    "        \"_score\": 2.1806526,\n",
    "        \"_source\": {\n",
    "          \"title\": \"The Great Gatsby\",\n",
    "          \"author\": \"F. Scott Fitzgerald\",\n",
    "          \"price\": 12.99\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"_index\": \"books\",\n",
    "        \"_type\": \"_doc\",\n",
    "        \"_id\": \"2\",\n",
    "        \"_score\": 1.9876543,\n",
    "        \"_source\": {\n",
    "          \"title\": \"Great Expectations\",\n",
    "          \"author\": \"Charles Dickens\",\n",
    "          \"price\": 10.50\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f9193",
   "metadata": {},
   "source": [
    "## Sort\n",
    "\n",
    "* can just add a sort parameter\n",
    "    - can sort by multiple fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f92895",
   "metadata": {},
   "outputs": [],
   "source": [
    "// GET /books/_search\n",
    "{\n",
    "  \"sort\": [\n",
    "    { \"price\": \"asc\" }\n",
    "  ],\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}\n",
    "\n",
    "// GET /books/_search\n",
    "{\n",
    "  \"sort\": [\n",
    "    { \"price\": \"asc\" },\n",
    "    { \"publish_date\": \"desc\" }\n",
    "  ],\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c89851",
   "metadata": {},
   "source": [
    "### Sorting By Script\n",
    "\n",
    "* allows sorting based on custom scripts using the \"Painless\" scripting language\n",
    "* useful when you need to sort by a computed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdae314",
   "metadata": {},
   "outputs": [],
   "source": [
    "// GET /books/_search\n",
    "{\n",
    "  \"sort\": [\n",
    "    {\n",
    "      \"_script\": {\n",
    "        \"type\": \"number\",\n",
    "        \"script\": {\n",
    "          \"source\": \"doc['price'].value * 0.9\"\n",
    "        },\n",
    "        \"order\": \"asc\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f801ce",
   "metadata": {},
   "source": [
    "### Sorting On Nested Fields\n",
    "\n",
    "* when sorting nested fields, you need to use a nested sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0fe2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "// GET /books/_search\n",
    "{\n",
    "  \"sort\": [\n",
    "    {\n",
    "      \"reviews.rating\": {\n",
    "        \"order\": \"desc\",\n",
    "        \"mode\": \"max\",\n",
    "        \"nested\": {\n",
    "          \"path\": \"reviews\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcc9c1",
   "metadata": {},
   "source": [
    "### Relevance-Based Sorting\n",
    "\n",
    "* if we don't specify sort order, Elasticsearch sorts results by relevance score (\\_score)\n",
    "* default scoring algorithm is closely related to TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "    - basically, it weighs frequency of a term heavily\n",
    "    - while also reducing weight if that term appears in a lot of documents\n",
    "    - for example: the term \"the\" has a high term frequency but also a very high document frequency\n",
    "        * we want a term to be highly frequent in a document but only if it's in a small subset of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2c043",
   "metadata": {},
   "source": [
    "## Pagination and Cursors\n",
    "\n",
    "* pagination: allows you to retrieve a subset of search results, typically used to display results across multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e21d71",
   "metadata": {},
   "source": [
    "### From/Size Pagination\n",
    "\n",
    "* simplest form of pagination\n",
    "    - from: starting index of results\n",
    "    - size: # of results to return\n",
    "* not efficient for deep pagination (10k+ results)\n",
    "    - this is due to overhead of sorting/fetching all preceding documents\n",
    "    - cluster needs to retrieve and sort all these documents on each request, which can be quite expensive\n",
    "        * Elasticsearch stores documents in shards\n",
    "        * pagination happens at the shard level\n",
    "        * then a global merge sort and reduce happens to return the # of documents needed for the query\n",
    "        * the rest get discard and only the # of size is returned\n",
    "    - e.g. from = 10,000 and size = 10\n",
    "        - Elasticsearch has to sort 10,010 results on each shard\n",
    "        - depending on # of shards, this equals to: # shards * 10,010 results\n",
    "        - then you must do a merge sort and reduce\n",
    "            * think about the merging K-sorted arrays leetcode question using a priority queue\n",
    "            * since the 10,010 results from each shard is already locally sorted, it just has to merge sort them\n",
    "                - it does not naively combine 10,010 * N results into one, sorts it, then reduces down to 10,010\n",
    "                - it always keeps it to 10,010 during the merging phase\n",
    "        - discard 10,000 results and only return 10, which is the size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "// GET /my_index/_search\n",
    "{\n",
    "  \"from\": 0,\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"elasticsearch\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59d381",
   "metadata": {},
   "source": [
    "### Search After\n",
    "\n",
    "* __more efficient for deep pagination__\n",
    "    - Elasticsearch knows exactly where to start for the next page\n",
    "    - this also has the advantages of:\n",
    "        * not missing any documents added in subsequent pages (even if new documents are added between requests)\n",
    "        * no duplicate results across pages\n",
    "    - but also the cons of:\n",
    "        * having to maintain state on the client side\n",
    "            - i.e. remember sort values of last document\n",
    "        * no random access to pages\n",
    "            - must always move forward since you can only search_after\n",
    "        * can also risk missing documents in previous pages if the underlying data was updated or deleted\n",
    "* uses sort values of the last result as the starting point for the next page\n",
    "* how it works:\n",
    "    1. don't include `search_after` parameter in first query\n",
    "    2. using the results of the first query, take the sort values of the last document\n",
    "    3. the sort values become the `search_after` parameter for the next query\n",
    "* in the example 1463538857 is the timestamp and 654323 is the \\_id of the last document in the previous page\n",
    "***\n",
    "* `search_after` requires a deterministic sort\n",
    "    - that's why we sort by date and \\_id here\n",
    "    - `search_after` then takes those 2 sort values and uses them as parameters\n",
    "        * in the example below, we use date and \\_id as the sort parameters\n",
    "        * notice how we also pass in a date and an id into `search_after`'s array\n",
    "    - __you usually need at least 2 fields: the first as a primary sort field and the second is the tie-breaker if you have duplicate values__\n",
    "        * if you can guarantee uniqueness, then 1 field is sufficient\n",
    "        * but \\_id is usually used as the tie-breaker since it's always unique\n",
    "* __the deterministic sort determines what `after` means__\n",
    "    - e.g. if you sort in descending order\n",
    "    | Document | Timestamp | Should shard scan?                |\n",
    "| -------- | --------- | --------------------------------- |\n",
    "| E        | 500       | ❌ (before 300 in descending sort) |\n",
    "| D        | 400       | ❌ (before 300 in descending sort) |\n",
    "| C        | 300       | ❌ (equal, already seen)           |\n",
    "| B        | 200       | ✅                                 |\n",
    "| A        | 100       | ✅                                 |\n",
    "\n",
    "    - if this were ascending order for timestamp, you would only care for documents D and E since they have timestamps after 300\n",
    "    | Document | Timestamp | `_id` | Should shard scan? |\n",
    "| -------- | --------- | ----- | ------------------ |\n",
    "| A        | 100       | \"A\"   | ❌ too early        |\n",
    "| B        | 200       | \"B\"   | ❌ too early        |\n",
    "| C        | 300       | \"C\"   | ❌ equal — skip     |\n",
    "| D        | 400       | \"D\"   | ✅ after            |\n",
    "| E        | 500       | \"E\"   | ✅ after            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "// GET /my_index/_search\n",
    "{\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"elasticsearch\"\n",
    "    }\n",
    "  },\n",
    "  \"sort\": [\n",
    "    {\"date\": \"desc\"},\n",
    "    {\"_id\": \"desc\"}\n",
    "  ],\n",
    "  \"search_after\": [1463538857, \"654323\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4521d",
   "metadata": {},
   "source": [
    "### Cursors\n",
    "\n",
    "* cursors provide a stateful way to paginate through search results\n",
    "    - solves problem of documents shifting underneath you\n",
    "    - requires a lot more overhead than previous pagination methods\n",
    "* it uses a `point in time (PIT)` API along with `search_after` for cursor-based pagination\n",
    "* __it basically creates a snapshot of the data__\n",
    "* how it works:\n",
    "    1. create a `PIT` which returns an ID\n",
    "    2. use the PIT ID in searches\n",
    "    3. for subsequent paginated searches, use the `search_after`with the PIT ID\n",
    "    4. close the PIT when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// POST /my_index/_pit?keep_alive=1m\n",
    "// which returns us a PIT ID\n",
    "\n",
    "// use the PIT for initial search\n",
    "// GET /_search\n",
    "{\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"elasticsearch\"\n",
    "    }\n",
    "  },\n",
    "  \"pit\": { // HERE!!!\n",
    "    \"id\": \"46To...\",\n",
    "    \"keep_alive\": \"1m\"\n",
    "  },\n",
    "  \"sort\": [\n",
    "    {\"_score\": \"desc\"},\n",
    "    {\"_id\": \"asc\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "// for subsequent searches, add search_after\n",
    "// GET /_search\n",
    "{\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"title\": \"elasticsearch\"\n",
    "    }\n",
    "  },\n",
    "  \"pit\": {\n",
    "    \"id\": \"46To...\",\n",
    "    \"keep_alive\": \"1m\"\n",
    "  },\n",
    "  \"sort\": [\n",
    "    {\"_score\": \"desc\"},\n",
    "    {\"_id\": \"asc\"}\n",
    "  ],\n",
    "  \"search_after\": [1.0, \"1234\"]\n",
    "}\n",
    "\n",
    "// close the PIT when done\n",
    "// DELETE /_pit\n",
    "{\n",
    "  \"id\" : \"46To...\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ab987",
   "metadata": {},
   "source": [
    "## How it Works\n",
    "\n",
    "* ES built on top of Apache Lucene\n",
    "    - Lucene = low-level search library\n",
    "    - handles the searching aspect of Elastic\n",
    "* ES handles the distributed systems part\n",
    "    - cluster coordination\n",
    "    - APIs\n",
    "    - aggregations\n",
    "    - real-time capabilities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69296c9e-92a5-4378-87b3-af3f245eaad2",
   "metadata": {},
   "source": [
    "## Cluster Architecture\n",
    "\n",
    "### Node Types\n",
    "\n",
    "* Elasticsearch is a __distributed search engine__\n",
    "    - you're actually creating multiple nodes when you create an Elasticsearch cluster\n",
    "* there are 5 different nodes:\n",
    "    1. __Master Node__: coordinates the cluster (think Admin)\n",
    "        - only node that can perform cluster-level operations\n",
    "        - i.e. adding/removing nodes\n",
    "        - or creating/deleting indices\n",
    "    2. __Data Node__: stores the data\n",
    "        - where your data is actually stored\n",
    "        - will have a lot of these in a big cluster\n",
    "    3. __Coordinating Node__: coordinates search requests across the cluster (frontend of your cluster)\n",
    "        - receives search request from client and sends it to the appropriate nodes\n",
    "    5. __Ingest Node__: responsible for data ingestion\n",
    "        - i.e. transforms the data and prepares it for indexing\n",
    "    7. __Machine Learning Node__: responsible for machine learning tasks\n",
    "* every instance of Elasticsearch can be of multiple types depending on its configurations\n",
    "    - e.g. an instance can be configured to be a master-eligible node and a coordinating node\n",
    "* each node type may also have its own dedicated host\n",
    "    - e.g. ingest node host might be CPU bound and have many processors\n",
    "    - or data node host might have high disk I/O or more memory\n",
    "* each node type also has specializations (Data tiers)\n",
    "    - e.g. data nodes can be hot, warm, cold, or frozen depending on how likely data is to be queried (e.g. recent or not) and whether it can change\n",
    "* when a cluster starts, you'll initially have a list of seed nodes that are master-eligible\n",
    "    - they then perform a leader election algorithm process to choose a master for the cluster\n",
    "    - only one node is allowed to be the active master while the other master-eligible nodes are on standby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae99ddc-ef9f-4a3e-ab8c-53d923e2aef5",
   "metadata": {},
   "source": [
    "## Data Nodes\n",
    "\n",
    "* primary function: store documents and optimize search\n",
    "    - think of it like a separate document database\n",
    "* a request has 2 phases:\n",
    "    1. query: grab the relevant docs\n",
    "    2. fetch: document IDs are pulled from the nodes optionally\n",
    "* data nodes house our `Elasticsearch indexes`, i.e. collections of documents, not like a database index\n",
    "    - each Index has `shards` of the data and their `replicas`\n",
    "    - inside each shard/replica are `Lucene indexes`\n",
    "    - inside of a Lucene Index are `Lucene Segments`\n",
    "* shards allow you to split up your data across hosts\n",
    "    - i.e. across multiple nodes in the cluster which improve performance and scalability\n",
    "    - searches done on multiple nodes in parallel and merged/sorted by the Coordinating Node\n",
    "* replica: exact copy of a shard\n",
    "    - they serve 2 purposes:\n",
    "        1. high availability => if one fails, you have the other to rely on\n",
    "        2. increased throughput => Coordinating node can load balance requests to primary shard or its replica\n",
    "* ES shards are 1:1 with Lucene indexes\n",
    "    - you can think of the ES operations on shards as proxy operations on the Lucene indexes underneath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6663e",
   "metadata": {},
   "source": [
    "### Lucene Segment CRUD\n",
    "\n",
    "* Lucene indexes made up of segments\n",
    "* Lucene Segment: __immutable__ containers of indexed data\n",
    "    - construct segments from multiple documents by batching writes together\n",
    "    - Inserts: we batch inserts together into a segment and flush it to disk\n",
    "    - when there are too many segments, Lucene merges them together to create a new segment\n",
    "        * the old segments are deleted\n",
    "    - Deletions: has a set of Deleted Identifiers\n",
    "        * when we query for a deleted document on a segment, it's treated as not being there even though the data is still there\n",
    "        * during segment merge operations, these deleted documents are cleaned up\n",
    "    - Updates: insert a new document with the updated information and soft delete the old document in the previous segment\n",
    "        * the old document will get cleaned up during segment merge operations\n",
    "    - __`basically: updates and deletions may only create new segments and do not modify existing ones.`__`\n",
    "* __UPDATES HAVE _WORSE_ PERFORMANCE THAN INSERTIONS BECAUSE OF THE OVERHEAD OF SOFT DELETIONS. THIS IS PART OF WHY ELASTICSEARCH IS NOT A GREAT FIT FOR DATA THAT UPDATES FREQUENTLY__\n",
    "* Pros of Immutable Segments:\n",
    "    - Improved write performance: new documents can be quickly added to new segments without modifying existing ones\n",
    "    - Efficient caching: since segments are immutable, they can be safely cached in memory or on SSD without worrying about consistency issues\n",
    "    - Simplified concurrency: read operations don't need to worry about data changing mid-query\n",
    "    - Easier recovery: in case of a crash, easier to recover from immutable segments as their state is known and consistent\n",
    "    - Optimized compression: immutable data can be more effectively compressed, saving dick space\n",
    "    - Faster searches: allows for optimized data structures and algorithms for searching\n",
    "* Cons of Immutable Segments:\n",
    "    - Requires periodic segment merges\n",
    "    - Temporary increased storage requirements before cleanup merge operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d08c08",
   "metadata": {},
   "source": [
    "### Lucene Segment Features\n",
    "\n",
    "* have data structures for search operations and the most important ones are:\n",
    "        1. inverted index\n",
    "        2. doc values\n",
    "    \n",
    "#### Inverted Index\n",
    "\n",
    "* the inverted index is the heart of Lucene\n",
    "* it's basically a hash map where:\n",
    "    - key = word/token\n",
    "    - value = list of documents word/token is in\n",
    "* this allows us to do O(1) lookups for things like finding all books that contain the word \"great\" in their title\n",
    "\n",
    "#### Doc Values\n",
    "\n",
    "* on-disk columnar-based data structure that allows us to easily access field values of a doc without having to query the entire thing up\n",
    "    - if you only need the price of a book, why do you care about the title, author, reviews, etc\n",
    "        * __this is a common problem for row-oriented databases like relational databases. even though I only need to access a single column, I need to read the entire row and index into it__\n",
    "    - this is a waste of space/memory since you need to load up the entire row just for a specific value\n",
    "    - what if you could just query the document ID and its corresponding price?\n",
    "* so using Doc Values, we can easily sort the results using a field's value\n",
    "* for example:\n",
    "    - row-based:\n",
    "| docId | Title                | Author              | Price |\n",
    "| ----- | -------------------- | ------------------- | ----- |\n",
    "| 101   | *The Great Gatsby*   | F. Scott Fitzgerald | \\$14  |\n",
    "| 102   | *Great Expectations* | Charles Dickens     | \\$12  |\n",
    "| 103   | *The Great Alone*    | Kristin Hannah      | \\$16  |\n",
    "    - colum based:\n",
    "        * think of it like a contiguous chunk of memory where each cell implicitly represents the docID\n",
    "            - keep in mind that doc values are on-disk data structures\n",
    "        * the reason why this works is because Lucene assigns each document in a segment a __sequential docID based on when it was inserted__\n",
    "            - the documents get assigned new docIDs when segments are merged\n",
    "            - a docID is a 32-bit number\n",
    "                * always starts at 0 per-segment\n",
    "                * maximum docID = # of documents in a segment\n",
    "                * deleted documents maintain their docIDs until the merging process; they are just treated as being non-existent\n",
    "                * docIDs are only used internally by Lucene and cannot be used externally\n",
    "            - there are 2 types of docIDs: global and per-segment\n",
    "                * global docID: (per-segment docID) + (segment's base docID offset)\n",
    "    ```\n",
    "    {\n",
    "  \"Title\":    [\"The Great Gatsby\", \"Great Expectations\", \"The Great Alone\"],\n",
    "  \"Author\":   [\"F. Scott Fitzgerald\", \"Charles Dickens\", \"Kristin Hannah\"],\n",
    "  \"Price\":    [14, 12, 16]\n",
    "    }\n",
    "    ```\n",
    "* __source__: [Lucene Index](https://lucene.apache.org/core/9_9_1/core/org/apache/lucene/index/package-summary.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b7df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b68862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a282c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71570a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e86068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
